{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet TER\n",
    "\n",
    "### Classification de tweets\n",
    "\n",
    "Le but de ce projet est de pouvoir faire la différence entre des tweets positifs et des tweets négatifs. Nous allons prendre les tweets comme un ensemble de symboles. \n",
    "\n",
    "Rappel, qu'est ce qu'un tweet. Un tweet est un petit message de 140 caractères maximum diffusé sur la plateforme Twitter. Les tweets d'un auteur sont diffusés auprès de ses followers ou abonnés, c'est à dire les individus ayant choisi de suivre la publication de ses petits messages. (cf http://www.definitions-marketing.com/definition/tweet/)  \n",
    "\n",
    "Nous avons donc à traiter des petits messages qui peuvent contenir des phrases, des émoticônes et/ou des mots clés précédés par le symbole \"#\".\n",
    "\n",
    "Nous allons donc développer un modele suivant ces étapes:\n",
    "\n",
    "**1) Exploration puis préparation des données sous forme exploitable.** \n",
    "C'est à dire créer un dictionnaire. Nous avons donc deux choix, prendre un vocabulaire de taille importante, et long au traitement, ou prendre un vocabulaire petit, pas nécésairement le plus complet mais plus éfficace. Si on prend la première approche (comme dans cet article https://www-cs.stanford.edu/people/alecmgo/papers/TwitterDistantSupervision09.pdf) on devra utiliser environ 400 à 500 mots. Cependant, si nous pouvons avoir accés à un vocabulaire plus grand et libre, nous l'utiliseront. \n",
    "Dans le corpus donné en exemple nous avons 1 578 627 phrases, c'est à dire des exemples de tweets. Cela nous fait un vocabulaire très grand. Il nous faudra donc le reduire à un nombre traitable.\n",
    "\n",
    "**2) Filtrage des données éventuel.**\n",
    "Ensuite pour le cas du filtrage, nous devront faire une analyse sur les mots clés les plus utilisés et les plus pertient. Le niveau d'optimisation que l'on pourra atteindre dependra de la taille initiale de notre vocabulaire mais plus il sera grand plus on pourra optimiser. On estime que même avec une grande base de données de mots il y aura des tweets que l'on ne pourra pas analyser completement, c'est à dire des tweets neutres, donc autant mieux se centrer sur ameliorer la réactivité de notre algorithme. \n",
    "\n",
    "**3)Préparation d'une partition : apprentissage, validation et test.**\n",
    "Pour finir, nous devrons utiliser plusieurs modèles afin de pouvoir correler nos résultats. Par exemple nous pouvons prendre un modèle basé sur les mots clés, mais aussi, comme décrit dans l'article vu avant, une méthode probabilistique, dite bayésienne naïve, par enthropie maximale et avec des vector machines, qui, en gros, cherchent la présence ou abscence d'une caracteristique d'un mot (pour voir s'il est positif ou négatif). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet:  @cupcake_kayla haha yes you do \r\n",
      "\n",
      "the number of training set: 100000\n",
      "the number of test set: 100000\n",
      "Nombre de tweets:  1578627\n"
     ]
    }
   ],
   "source": [
    "#this version is to find how many training_tweets\n",
    "#try to create a dictionary\n",
    "#So what we do is go through the text=ligne[3], if the word of ligne[3:] not in the dictionary we put it in\n",
    "#otherwise,we do nothing\n",
    "#this is the attribute of each line\n",
    "#the type of line <type 'str'>\n",
    "#line: 1578627,0,Sentiment140,\"Zzzzzzzzzzzzzzzzzzz, I wish \"\n",
    "# we stock all the sentence into the X_train\n",
    "# the sentiment into the Y_train\n",
    "import sys\n",
    "import numpy as np\n",
    "filename = 'Dataset.csv'\n",
    "\n",
    "nbLignes = 0\n",
    "\n",
    "X_train=[]\n",
    "Y_train=[]\n",
    "\n",
    "for line in open(filename,\"r\"):\n",
    "    ligne=line.split(',')\n",
    "    text=''\n",
    "    for i in range(3,len(ligne)):\n",
    "        if (i!=len(ligne)-1):\n",
    "            text=text+ligne[i]+\",\"\n",
    "        else:\n",
    "            text+=ligne[i]\n",
    "    X_train.append(text)\n",
    "    Y_train.append(ligne[1])\n",
    "    nbLignes=nbLignes+1\n",
    "    \n",
    "X_train=np.asarray(X_train)\n",
    "Y_train=np.asarray(Y_train)\n",
    "\n",
    "X_test=X_train[-100000:]\n",
    "Y_test=Y_train[-100000:]\n",
    "\n",
    "X_train=X_train[1:100001]\n",
    "Y_train=Y_train[1:100001]\n",
    "\n",
    "print \"tweet: \",X_train[-1]\n",
    "print \"the number of training set:\",len(X_train)\n",
    "print \"the number of test set:\",len(X_test)\n",
    "print \"Nombre de tweets: \", nbLignes-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the length of the dictionary: 118257\n"
     ]
    }
   ],
   "source": [
    "dictionary={}\n",
    "dictionary_inverse={}\n",
    "def get_word(x):\n",
    "    word=\"\"\n",
    "    word_list=[]\n",
    "    flag=True\n",
    "    for i in range(len(x)):\n",
    "        if x[i].isalpha() or x[i]==\"@\" or x[i]==\"&\":\n",
    "            if flag:\n",
    "                word+=x[i]\n",
    "                if i+1==len(x):\n",
    "                    word_list.append(word)\n",
    "            else:\n",
    "                flag=True\n",
    "                word+=x[i]\n",
    "\n",
    "        else:\n",
    "            flag=False\n",
    "            if word!=\"\":\n",
    "                word_list.append(word)\n",
    "            word=\"\"\n",
    "        if word==\"http\" or word==\"www\":\n",
    "            word_list.append(x)\n",
    "            break\n",
    "    return word_list\n",
    "couts=[]\n",
    "k=0\n",
    "for sentense in X_train:\n",
    "    word_list=get_word(sentense)\n",
    "    for word in word_list:\n",
    "        if word not in dictionary:\n",
    "            dictionary[word]=k\n",
    "            k+=1\n",
    "            dictionary_inverse[k]=word\n",
    "            couts.append(1)\n",
    "        else:\n",
    "            index=dictionary[word]\n",
    "            couts[index]+=1\n",
    "\n",
    "print \"the length of the dictionary:\",len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of the vocabulary 4098\n"
     ]
    }
   ],
   "source": [
    "vocab_size=0\n",
    "for k in couts:\n",
    "    if(k>20):\n",
    "        if (k<10000):\n",
    "            vocab_size+=1\n",
    "            \n",
    "print \"the size of the vocabulary\",vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the length of the new_dictionary: 4098\n",
      "the value max:  4100\n",
      "is\n"
     ]
    }
   ],
   "source": [
    "new_dictionary={}\n",
    "new_dictionary_inverse={}\n",
    "k=2\n",
    "for i in range(len(couts)):\n",
    "    if (couts[i]>20):\n",
    "        if (couts[i]<10000):\n",
    "            word=dictionary_inverse[i]\n",
    "            new_dictionary[word]=k\n",
    "            new_dictionary_inverse[k]=word\n",
    "            k+=1\n",
    "print \"the length of the new_dictionary:\",len(new_dictionary)\n",
    "print \"the value max: \",k\n",
    "print new_dictionary_inverse[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The size of the new_dictionary is 29104\n",
    "\n",
    "That is the size of the vacabulary and with 4 words to replace the word we can't recognize.\n",
    "\n",
    "new_dictionary is {word: index}\n",
    "new_dictionary_inverse is {index:word} \n",
    "\n",
    "The next step is trying to make the X_train represent in number\n",
    "\n",
    "train and test is the np.array list that represente the word in the l'index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change_into_number(sentense):\n",
    "    word_list=get_word(sentense)\n",
    "    l=[1 for i in range(len(word_list))]\n",
    "    for i in range(len(word_list)):\n",
    "        if word_list[i] in new_dictionary:\n",
    "            k=new_dictionary[word_list[i]]\n",
    "            l[i]=k\n",
    "    return l\n",
    "\n",
    "New_X_train=[]\n",
    "\n",
    "for tweet in X_train:\n",
    "    New_X_train.append(change_into_number(tweet))\n",
    "train=np.asarray(New_X_train)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "New_X_test=[]\n",
    "for sentense in X_test:\n",
    "    New_X_test.append(change_into_number(sentense))\n",
    "test=np.asarray(New_X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 1, 503, 1, 512, 1, 1, 71, 102, 440, 1]\n"
     ]
    }
   ],
   "source": [
    "print test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start construct the vector of train\n",
      "Start construc the vector of test\n",
      "End of constructing\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "def sent2binaryVector (sentence): \n",
    "    v = np.zeros([vocab_size])\n",
    "    for i in range(len(sentence)):\n",
    "        v[sentence[i]-1]=1 \n",
    "    return v\n",
    "\n",
    "\n",
    "\n",
    "def convertCorpus2binary(corpus):\n",
    "    M = np.zeros([len(corpus),vocab_size])\n",
    "    i=0\n",
    "    for x in corpus:\n",
    "        v = sent2binaryVector(x)\n",
    "        M[i,:] = v\n",
    "        i+=1\n",
    "    return M\n",
    "\n",
    "print \"Start construct the vector of train\"\n",
    "Vtrain =sequence.pad_sequences(train,maxlen=140)\n",
    "print \"Start construc the vector of test\"\n",
    "Vtest = sequence.pad_sequences(test,maxlen=140)\n",
    "print \"End of constructing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0 10 11 12  1]\n"
     ]
    }
   ],
   "source": [
    "print Vtrain[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              omg its already 7:30 :O\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print X_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 11, 12, 1]\n"
     ]
    }
   ],
   "source": [
    "print train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 32, input_length=140))\n",
    "model.add(Convolution1D(nb_filter=32, filter_length=3, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_length=140))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size+2, output_dim=50, input_length=140))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_7 (Embedding)          (None, 140, 50)       205000      embedding_input_7[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 7000)          0           embedding_7[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_22 (Dense)                 (None, 100)           700100      flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 100)           0           dense_22[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_23 (Dense)                 (None, 1)             101         activation_5[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 905,201\n",
      "Trainable params: 905,201\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_22 (Embedding)         (None, 140, 50)       205000                                       \n",
      "____________________________________________________________________________________________________\n",
      "dense_30 (Dense)                 (None, 140, 100)      5100        merge_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 140, 100)      0           dense_30[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 14000)         0           activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_31 (Dense)                 (None, 1)             14001       flatten_3[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 224,101\n",
      "Trainable params: 224,101\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 100000 samples, validate on 100000 samples\n",
      "Epoch 1/5\n",
      "100000/100000 [==============================] - 95s - loss: 0.5875 - acc: 0.6909 - val_loss: 0.5889 - val_acc: 0.6800\n",
      "Epoch 2/5\n",
      "100000/100000 [==============================] - 71s - loss: 0.5573 - acc: 0.7175 - val_loss: 0.5793 - val_acc: 0.6902\n",
      "Epoch 3/5\n",
      "100000/100000 [==============================] - 83s - loss: 0.5425 - acc: 0.7271 - val_loss: 0.5984 - val_acc: 0.6756\n",
      "Epoch 4/5\n",
      "100000/100000 [==============================] - 95s - loss: 0.5247 - acc: 0.7393 - val_loss: 0.6103 - val_acc: 0.6735\n",
      "Epoch 5/5\n",
      "100000/100000 [==============================] - 95s - loss: 0.5049 - acc: 0.7523 - val_loss: 0.6343 - val_acc: 0.6657\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.core import Merge\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(input_dim=vocab_size+2, output_dim=50, input_length=140))\n",
    "model2 = Sequential()\n",
    "model2.add(Merge([model1,model1], mode='ave'))\n",
    "model2.add(Dense(100))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "model2.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model2.summary()\n",
    "history = model2.fit(Vtrain, Y_train,\n",
    "        nb_epoch=5,\n",
    "        batch_size=32,\n",
    "        validation_data=(Vtest, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.callbacks.History'>\n",
      "{'acc': [0.69094, 0.71753999999999996, 0.72709999999999997, 0.73926000000000003, 0.75231000000000003], 'loss': [0.58745762008666991, 0.55734222839355474, 0.54246665940284733, 0.52469838127136226, 0.5049039455986023], 'val_acc': [0.68003999999999998, 0.69015000000000004, 0.67559000000000002, 0.67345999999999995, 0.66566000000000003], 'val_loss': [0.58893821722507478, 0.57932377939224244, 0.59838678619861607, 0.61031226181983944, 0.63428858681201938]}\n",
      "[0, 1, 2, 3, 4]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgsAAAFyCAYAAAB7mplaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16c127c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print type(history)\n",
    "print history.history\n",
    "print history.epoch\n",
    "def graph(history,flag):\n",
    "    plt.ylim(0,+1)\n",
    "    if flag:\n",
    "        plt.plot(np.arange(len(history.epoch)), history.history['acc'])\n",
    "    else:\n",
    "        plt.plot(np.arange(len(history.epoch)), history.history['val_acc'])\n",
    "    plt.title(\"the history\")\n",
    "    plt.show()\n",
    "graph(history,False)\n",
    "poid=model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.4869796 , -0.171763  , -0.06582582, ...,  0.20570605,\n",
      "        -0.2793228 ,  0.03776712],\n",
      "       [ 0.30103487,  0.73684603, -0.06986356, ...,  0.24575271,\n",
      "         0.33929613, -0.32587844],\n",
      "       [ 0.1549482 ,  0.29789916,  0.57141888, ...,  0.15350258,\n",
      "        -0.22219868,  0.06145204],\n",
      "       ..., \n",
      "       [ 0.15596038,  0.32237813, -0.10899381, ...,  0.61173278,\n",
      "         0.44018126, -0.17855947],\n",
      "       [-0.03467021,  0.58533984, -0.27004698, ...,  0.02554657,\n",
      "         0.70859587, -0.33603677],\n",
      "       [-0.57472509,  0.27670363, -0.5517773 , ..., -0.52729112,\n",
      "         0.31567031,  0.58021098]], dtype=float32), array([[ 0.47967777,  0.43723997, -0.1912353 , ...,  0.38028565,\n",
      "         0.10423629, -0.0742928 ],\n",
      "       [ 0.34948862,  0.6403178 , -0.34969246, ...,  0.49553847,\n",
      "         0.46800193, -0.49837932],\n",
      "       [-0.052233  ,  0.03036935,  0.49862486, ..., -0.15574591,\n",
      "         0.26214206, -0.17356911],\n",
      "       ..., \n",
      "       [ 0.42346421,  0.51658422, -0.4979386 , ...,  0.58158886,\n",
      "         0.0616531 , -0.41638792],\n",
      "       [ 0.13673507,  0.55820775, -0.37936524, ...,  0.53864276,\n",
      "         0.64038205, -0.44329506],\n",
      "       [-0.25686267,  0.277787  ,  0.05902732, ..., -0.33393312,\n",
      "        -0.25038317,  0.55459964]], dtype=float32), array([[ 0.46387345,  0.31275791,  0.03834303, ...,  0.22589625,\n",
      "         0.15060255, -0.18574817],\n",
      "       [ 0.28129897,  0.63214964, -0.47594327, ...,  0.50168973,\n",
      "         0.18509254, -0.59033281],\n",
      "       [ 0.18313444, -0.0076772 ,  0.4851099 , ...,  0.07120704,\n",
      "        -0.26281026,  0.32501829],\n",
      "       ..., \n",
      "       [-0.20913965,  0.20426667, -0.16695556, ...,  0.57496089,\n",
      "         0.26821819,  0.23018746],\n",
      "       [-0.05224783,  0.40103623, -0.28939375, ...,  0.26782322,\n",
      "         0.59025192, -0.42244822],\n",
      "       [-0.58188373,  0.29241744, -0.48438048, ...,  0.13019788,\n",
      "        -0.53363717,  0.54166162]], dtype=float32), array([[ 0.46069899,  0.038347  , -0.0625184 , ...,  0.18340829,\n",
      "         0.14131556, -0.01743164],\n",
      "       [ 0.34768143,  0.60859793, -0.03802243, ...,  0.51779461,\n",
      "         0.54525256, -0.39652517],\n",
      "       [-0.10870737, -0.0088372 ,  0.48354122, ...,  0.09708706,\n",
      "        -0.27504832,  0.11826047],\n",
      "       ..., \n",
      "       [ 0.21672465,  0.10921384,  0.04287441, ...,  0.55620593,\n",
      "         0.08237612,  0.1990647 ],\n",
      "       [ 0.30212644,  0.38424072,  0.15159832, ...,  0.35127902,\n",
      "         0.57526481,  0.04785023],\n",
      "       [-0.60326177,  0.39347962, -0.68229616, ..., -0.3881512 ,\n",
      "         0.4640958 ,  0.50346512]], dtype=float32), array([[ 0.45458847,  0.29989025, -0.01790239, ..., -0.10653409,\n",
      "         0.18189268, -0.13771699],\n",
      "       [-0.03467021,  0.58533984, -0.27004698, ...,  0.02554657,\n",
      "         0.70859587, -0.33603677],\n",
      "       [ 0.25863895,  0.1509909 ,  0.47192609, ..., -0.19073762,\n",
      "        -0.15622361,  0.2293361 ],\n",
      "       ..., \n",
      "       [-0.0171217 ,  0.07153446, -0.24506216, ...,  0.55424023,\n",
      "         0.20073329, -0.32789904],\n",
      "       [ 0.34768143,  0.60859793, -0.03802243, ...,  0.51779461,\n",
      "         0.54525256, -0.39652517],\n",
      "       [-0.07710253,  0.39154136, -0.15052275, ..., -0.13754272,\n",
      "         0.07292891,  0.47911593]], dtype=float32), array([[ 0.45236593,  0.06773867,  0.25177789, ..., -0.09610291,\n",
      "        -0.07577898,  0.08032534],\n",
      "       [ 0.03387979,  0.58283234, -0.3831155 , ...,  0.43690062,\n",
      "        -0.13722292, -0.10827637],\n",
      "       [-0.12312154,  0.12126698,  0.45950812, ...,  0.14540687,\n",
      "         0.08353439, -0.0251594 ],\n",
      "       ..., \n",
      "       [-0.07047652,  0.17740624,  0.11260949, ...,  0.54682833,\n",
      "         0.21891893, -0.11530517],\n",
      "       [-0.12627202,  0.20616642, -0.15764986, ...,  0.24136226,\n",
      "         0.53878272,  0.32775229],\n",
      "       [-0.6285606 ,  0.1893975 , -0.19183441, ..., -0.21466143,\n",
      "        -0.45039535,  0.4747169 ]], dtype=float32), array([[ 0.44408715,  0.39330694, -0.43286929, ...,  0.45203203,\n",
      "         0.28247875, -0.35501784],\n",
      "       [ 0.38917282,  0.57361376,  0.12382874, ..., -0.07806119,\n",
      "        -0.20654581, -0.30431396],\n",
      "       [ 0.12242086,  0.0986258 ,  0.45183662, ...,  0.04800371,\n",
      "        -0.15100396,  0.1159666 ],\n",
      "       ..., \n",
      "       [ 0.13673507,  0.55820775, -0.37936524, ...,  0.53864276,\n",
      "         0.64038205, -0.44329506],\n",
      "       [ 0.14186898,  0.32848582, -0.04389707, ..., -0.10943425,\n",
      "         0.53597426, -0.41640326],\n",
      "       [-0.14051516, -0.0203636 ,  0.06142214, ...,  0.10162468,\n",
      "        -0.16441602,  0.46747035]], dtype=float32), array([[ 0.44328505,  0.37743571, -0.14061446, ...,  0.0434626 ,\n",
      "        -0.2269018 , -0.05458133],\n",
      "       [ 0.01247046,  0.56996328, -0.04264196, ..., -0.01056825,\n",
      "         0.20381634, -0.23387592],\n",
      "       [-0.16640045, -0.02631179,  0.4470827 , ...,  0.25721633,\n",
      "         0.17182907, -0.03286856],\n",
      "       ..., \n",
      "       [ 0.21277677,  0.22326934,  0.14526618, ...,  0.51804626,\n",
      "         0.35906032,  0.07970414],\n",
      "       [ 0.1546507 ,  0.19912507, -0.03406437, ...,  0.41325694,\n",
      "         0.53491902, -0.06250317],\n",
      "       [-0.52279186,  0.2486234 , -0.13526307, ..., -0.19511418,\n",
      "        -0.48577893,  0.46634284]], dtype=float32), array([[ 0.43856078,  0.3084605 ,  0.42530897, ..., -0.10124639,\n",
      "        -0.28888786,  0.2171354 ],\n",
      "       [-0.02172896,  0.56836432,  0.1797324 , ..., -0.08315686,\n",
      "        -0.03839759,  0.15003584],\n",
      "       [ 0.10599386, -0.01595607,  0.44692102, ...,  0.21820275,\n",
      "        -0.08425013,  0.15210451],\n",
      "       ..., \n",
      "       [ 0.34768143,  0.60859793, -0.03802243, ...,  0.51779461,\n",
      "         0.54525256, -0.39652517],\n",
      "       [ 0.24729452,  0.34627706, -0.27498907, ...,  0.23894569,\n",
      "         0.52620596, -0.37948668],\n",
      "       [ 0.18321757,  0.25514272,  0.123073  , ...,  0.12847254,\n",
      "        -0.02244013,  0.44989198]], dtype=float32), array([[ 0.43674785, -0.30280381,  0.14315766, ..., -0.09180534,\n",
      "        -0.22043325, -0.25090665],\n",
      "       [ 0.13294008,  0.5669055 , -0.24312474, ...,  0.37960318,\n",
      "        -0.01226395,  0.13132963],\n",
      "       [-0.06638334,  0.15524133,  0.44618711, ...,  0.21407837,\n",
      "         0.10887446, -0.08002268],\n",
      "       ..., \n",
      "       [ 0.40281633,  0.51830202, -0.3615523 , ...,  0.51328766,\n",
      "         0.28931636, -0.32038039],\n",
      "       [-0.13503981,  0.09390361, -0.10109784, ...,  0.23182374,\n",
      "         0.51784146, -0.31788993],\n",
      "       [-0.32822606,  0.10908073, -0.40652719, ..., -0.06430761,\n",
      "        -0.11580461,  0.44927108]], dtype=float32)]\n",
      "-------------------\n",
      "[array([[-0.7573849 ,  0.29885709, -0.76661754, ..., -0.39640287,\n",
      "         0.35616112,  0.27442378],\n",
      "       [-0.11067475, -0.58450985, -0.20620614, ...,  0.24564575,\n",
      "         0.30847731, -0.19183719],\n",
      "       [-0.7573849 ,  0.29885709, -0.76661754, ..., -0.39640287,\n",
      "         0.35616112,  0.27442378],\n",
      "       ..., \n",
      "       [-0.26610917,  0.24146885, -0.3683129 , ..., -0.63108212,\n",
      "         0.19044174,  0.3331556 ],\n",
      "       [-0.65348178,  0.25129443, -0.12635119, ..., -0.06507047,\n",
      "        -0.64152116,  0.36972618],\n",
      "       [ 0.37214512,  0.26837692,  0.23295519, ...,  0.18299034,\n",
      "         0.12447531, -0.60427833]], dtype=float32), array([[-0.65348178,  0.25129443, -0.12635119, ..., -0.06507047,\n",
      "        -0.64152116,  0.36972618],\n",
      "       [ 0.0563415 , -0.53487349,  0.08107089, ..., -0.11718873,\n",
      "        -0.36455971,  0.10077699],\n",
      "       [-0.60326177,  0.39347962, -0.68229616, ..., -0.3881512 ,\n",
      "         0.4640958 ,  0.50346512],\n",
      "       ..., \n",
      "       [-0.06673731,  0.08434291, -0.18108182, ..., -0.6022625 ,\n",
      "        -0.12439658,  0.37293383],\n",
      "       [-0.37226161,  0.24560317, -0.3069115 , ..., -0.38866591,\n",
      "        -0.58499146,  0.2035763 ],\n",
      "       [ 0.28129897,  0.63214964, -0.47594327, ...,  0.50168973,\n",
      "         0.18509254, -0.59033281]], dtype=float32), array([[-0.64653218,  0.33271125, -0.66299033, ..., -0.17244664,\n",
      "         0.41126093,  0.3981972 ],\n",
      "       [-0.13238277, -0.51114881, -0.27889201, ..., -0.15595102,\n",
      "         0.03969942, -0.12674886],\n",
      "       [-0.64653218,  0.33271125, -0.66299033, ..., -0.17244664,\n",
      "         0.41126093,  0.3981972 ],\n",
      "       ..., \n",
      "       [-0.05662676, -0.27758285,  0.11674562, ..., -0.58529055,\n",
      "         0.01073722,  0.00887234],\n",
      "       [-0.36113611,  0.1910315 ,  0.04997607, ...,  0.10062435,\n",
      "        -0.57256985,  0.36317691],\n",
      "       [ 0.1625541 ,  0.10066258, -0.14688633, ..., -0.03439219,\n",
      "         0.0669829 , -0.5759179 ]], dtype=float32), array([[-0.6285606 ,  0.1893975 , -0.19183441, ..., -0.21466143,\n",
      "        -0.45039535,  0.4747169 ],\n",
      "       [-0.15081227, -0.48459962, -0.25904801, ..., -0.03540403,\n",
      "         0.14304776, -0.36382583],\n",
      "       [-0.56263053,  0.16812208, -0.66185117, ..., -0.47344398,\n",
      "         0.3239812 ,  0.22126932],\n",
      "       ..., \n",
      "       [-0.41072217,  0.11747542, -0.37148413, ..., -0.58295619,\n",
      "         0.29485163,  0.34842476],\n",
      "       [-0.23545064, -0.14433664, -0.08534428, ..., -0.10524909,\n",
      "        -0.5473696 ,  0.04244811],\n",
      "       [-0.39071715,  0.24135283, -0.08342395, ...,  0.08695783,\n",
      "         0.05116927, -0.57263482]], dtype=float32), array([[-0.60326177,  0.39347962, -0.68229616, ..., -0.3881512 ,\n",
      "         0.4640958 ,  0.50346512],\n",
      "       [-0.10668475, -0.47609985,  0.13921286, ...,  0.05964733,\n",
      "        -0.43332326,  0.04266593],\n",
      "       [-0.58919758, -0.09139566, -0.65218997, ...,  0.08405162,\n",
      "         0.14534225,  0.03444892],\n",
      "       ..., \n",
      "       [-0.23177938, -0.02268472, -0.15663837, ..., -0.57892501,\n",
      "        -0.04497129,  0.14126714],\n",
      "       [-0.39183694,  0.05359373,  0.02242478, ..., -0.23000175,\n",
      "        -0.54647619,  0.38357633],\n",
      "       [ 0.05642086,  0.4703258 , -0.44733074, ..., -0.03703918,\n",
      "         0.49525267, -0.55304307]], dtype=float32), array([[-0.58919758, -0.09139566, -0.65218997, ...,  0.08405162,\n",
      "         0.14534225,  0.03444892],\n",
      "       [-0.14847684, -0.45987803, -0.31423405, ..., -0.26090032,\n",
      "         0.00927565, -0.12987623],\n",
      "       [-0.54291672,  0.34575486, -0.58871156, ...,  0.019338  ,\n",
      "         0.26863036,  0.21846344],\n",
      "       ..., \n",
      "       [-0.57472509,  0.27670363, -0.5517773 , ..., -0.52729112,\n",
      "         0.31567031,  0.58021098],\n",
      "       [-0.58188373,  0.29241744, -0.48438048, ...,  0.13019788,\n",
      "        -0.53363717,  0.54166162],\n",
      "       [ 0.20268996,  0.26427099, -0.16163389, ...,  0.21341456,\n",
      "         0.26032183, -0.54671007]], dtype=float32), array([[-0.58188373,  0.29241744, -0.48438048, ...,  0.13019788,\n",
      "        -0.53363717,  0.54166162],\n",
      "       [ 0.07173485, -0.44952425, -0.08913696, ..., -0.21861483,\n",
      "         0.18492557,  0.0265961 ],\n",
      "       [ 0.41270593,  0.26867673, -0.5681091 , ...,  0.31747651,\n",
      "         0.05840562, -0.11087345],\n",
      "       ..., \n",
      "       [-0.37552235,  0.09059595, -0.16329262, ..., -0.50673103,\n",
      "        -0.15018052, -0.03575084],\n",
      "       [-0.07032789,  0.26201376,  0.10987502, ..., -0.20852138,\n",
      "        -0.50206387,  0.02869714],\n",
      "       [-0.10894746,  0.17107049, -0.07421543, ...,  0.13398486,\n",
      "        -0.10387553, -0.54141229]], dtype=float32), array([[-0.57472509,  0.27670363, -0.5517773 , ..., -0.52729112,\n",
      "         0.31567031,  0.58021098],\n",
      "       [-0.01218448, -0.44926792, -0.03030721, ...,  0.16382319,\n",
      "        -0.03847454, -0.40568715],\n",
      "       [-0.52155185,  0.08002865, -0.5638653 , ..., -0.1081182 ,\n",
      "         0.1772114 ,  0.09113   ],\n",
      "       ..., \n",
      "       [-0.52374101,  0.36292183, -0.47584838, ..., -0.49332803,\n",
      "         0.19968985,  0.40209699],\n",
      "       [ 0.19208586, -0.23496783, -0.02272454, ...,  0.04025583,\n",
      "        -0.48910099,  0.0386216 ],\n",
      "       [ 0.04001459, -0.02442872, -0.11269437, ...,  0.00740388,\n",
      "        -0.07441785, -0.53690803]], dtype=float32), array([[-0.56407511,  0.38289022, -0.44162697, ..., -0.28325802,\n",
      "        -0.2115054 ,  0.28843969],\n",
      "       [ 0.09336759, -0.44612423,  0.09483142, ...,  0.1893934 ,\n",
      "        -0.12959161, -0.35546836],\n",
      "       [-0.56405979, -0.02933131, -0.56135082, ..., -0.00091644,\n",
      "         0.36079541, -0.26810798],\n",
      "       ..., \n",
      "       [-0.36916903,  0.08324838, -0.29533881, ..., -0.48525041,\n",
      "         0.22651124,  0.2780717 ],\n",
      "       [-0.27892449,  0.03345561, -0.30915123, ..., -0.16803382,\n",
      "        -0.48853731,  0.20707092],\n",
      "       [-0.19682384,  0.2073255 , -0.24322474, ...,  0.28211957,\n",
      "         0.15675811, -0.53033894]], dtype=float32), array([[-0.56405979, -0.02933131, -0.56135082, ..., -0.00091644,\n",
      "         0.36079541, -0.26810798],\n",
      "       [ 0.01541182, -0.44112122, -0.1873489 , ..., -0.14955358,\n",
      "         0.04811639, -0.04041284],\n",
      "       [-0.32198241,  0.23852207, -0.554685  , ..., -0.25263736,\n",
      "        -0.1319173 ,  0.26887247],\n",
      "       ..., \n",
      "       [-0.40959504, -0.01894976, -0.41179153, ..., -0.48429561,\n",
      "         0.33482918,  0.31950405],\n",
      "       [-0.52279186,  0.2486234 , -0.13526307, ..., -0.19511418,\n",
      "        -0.48577893,  0.46634284],\n",
      "       [ 0.19173244,  0.48200637, -0.37829858, ...,  0.48104754,\n",
      "         0.39529669, -0.52669114]], dtype=float32), array([[-0.56263053,  0.16812208, -0.66185117, ..., -0.47344398,\n",
      "         0.3239812 ,  0.22126932],\n",
      "       [ 0.17821872, -0.42694488,  0.24686557, ...,  0.24797408,\n",
      "        -0.24427083, -0.25952545],\n",
      "       [-0.57472509,  0.27670363, -0.5517773 , ..., -0.52729112,\n",
      "         0.31567031,  0.58021098],\n",
      "       ..., \n",
      "       [-0.56263053,  0.16812208, -0.66185117, ..., -0.47344398,\n",
      "         0.3239812 ,  0.22126932],\n",
      "       [-0.11006179,  0.10204035,  0.36299378, ...,  0.11615453,\n",
      "        -0.48395038,  0.20001152],\n",
      "       [ 0.06466052,  0.25916001,  0.03065111, ...,  0.15103757,\n",
      "         0.2103745 , -0.52142012]], dtype=float32), array([[-0.54291672,  0.34575486, -0.58871156, ...,  0.019338  ,\n",
      "         0.26863036,  0.21846344],\n",
      "       [ 0.0877838 , -0.42657083, -0.20451225, ..., -0.16150872,\n",
      "         0.09710959,  0.10194691],\n",
      "       [-0.44049478, -0.00076476, -0.54504532, ...,  0.11503674,\n",
      "         0.12109219,  0.03542019],\n",
      "       ..., \n",
      "       [-0.36157453, -0.08954833, -0.03287405, ..., -0.44459605,\n",
      "        -0.18302242,  0.0447439 ],\n",
      "       [-0.23287962,  0.20416512, -0.35272977, ..., -0.17056686,\n",
      "        -0.47349226,  0.159126  ],\n",
      "       [ 0.27610269, -0.07495857, -0.19180641, ...,  0.20207733,\n",
      "         0.33276042, -0.51659381]], dtype=float32), array([[-0.53730458,  0.32127795, -0.30759361, ..., -0.12542745,\n",
      "        -0.16870101,  0.12855898],\n",
      "       [ 0.11707944, -0.42045864, -0.10816662, ..., -0.12128193,\n",
      "        -0.15727188,  0.04522581],\n",
      "       [ 0.14515997, -0.1324565 , -0.52423012, ...,  0.29772654,\n",
      "        -0.0818299 ,  0.07624925],\n",
      "       ..., \n",
      "       [ 0.02275282, -0.01875692, -0.28184909, ..., -0.43969101,\n",
      "        -0.06039957, -0.08810459],\n",
      "       [ 0.18776381,  0.1118114 ,  0.10424718, ..., -0.12685788,\n",
      "        -0.46938071,  0.10222436],\n",
      "       [-0.14318119, -0.39147648,  0.07159165, ...,  0.03758712,\n",
      "        -0.01686617, -0.51532304]], dtype=float32), array([[-0.53672546,  0.08045514, -0.373124  , ...,  0.18120703,\n",
      "         0.44390354, -0.0877964 ],\n",
      "       [-0.1070265 , -0.4173826 , -0.24106948, ...,  0.12232745,\n",
      "        -0.17095445, -0.11271489],\n",
      "       [-0.30209577,  0.25729108, -0.50248516, ..., -0.06079005,\n",
      "         0.08852898,  0.31879908],\n",
      "       ..., \n",
      "       [-0.15620314, -0.04591478, -0.11647828, ..., -0.4395864 ,\n",
      "         0.22952719,  0.11731812],\n",
      "       [-0.11087537,  0.19664487, -0.17639132, ...,  0.13518107,\n",
      "        -0.46550184,  0.27867749],\n",
      "       [-0.11334646, -0.03053258, -0.0279065 , ...,  0.25134897,\n",
      "         0.39891797, -0.51502895]], dtype=float32), array([[-0.53568834,  0.14744402, -0.33517456, ..., -0.19986694,\n",
      "         0.07944221,  0.26304057],\n",
      "       [-0.24547626, -0.41047624, -0.06108323, ..., -0.03859669,\n",
      "        -0.29480013,  0.07826489],\n",
      "       [ 0.42346421,  0.51658422, -0.4979386 , ...,  0.58158886,\n",
      "         0.0616531 , -0.41638792],\n",
      "       ..., \n",
      "       [-0.28544962,  0.05428163, -0.19755954, ..., -0.43467432,\n",
      "        -0.26476356, -0.1581832 ],\n",
      "       [-0.6285606 ,  0.1893975 , -0.19183441, ..., -0.21466143,\n",
      "        -0.45039535,  0.4747169 ],\n",
      "       [ 0.02046548,  0.32861704,  0.04496129, ...,  0.24830091,\n",
      "         0.11601497, -0.5120182 ]], dtype=float32), array([[-0.5302636 , -0.03150614, -0.47504845, ...,  0.43710402,\n",
      "        -0.29813415, -0.11405174],\n",
      "       [-0.14346859, -0.40655065, -0.04618295, ..., -0.03974251,\n",
      "         0.18516096, -0.00362014],\n",
      "       [-0.46893615,  0.0971298 , -0.49641734, ..., -0.34829956,\n",
      "         0.21858338,  0.3953383 ],\n",
      "       ..., \n",
      "       [-0.14867753,  0.10281714, -0.21544185, ..., -0.43419302,\n",
      "        -0.1115839 , -0.00942268],\n",
      "       [-0.40507537,  0.1261168 , -0.38030821, ..., -0.15191276,\n",
      "        -0.45002732,  0.02088304],\n",
      "       [ 0.15338601,  0.24494667,  0.03583927, ...,  0.17608419,\n",
      "         0.11144638, -0.5056361 ]], dtype=float32), array([[-0.52993929,  0.26917124, -0.48663327, ...,  0.12925282,\n",
      "         0.15255432, -0.0674707 ],\n",
      "       [-0.03169777, -0.40504149, -0.38599917, ...,  0.06827281,\n",
      "        -0.11811536, -0.21710837],\n",
      "       [-0.52993929,  0.26917124, -0.48663327, ...,  0.12925282,\n",
      "         0.15255432, -0.0674707 ],\n",
      "       ..., \n",
      "       [-0.08991434, -0.07226115, -0.2368249 , ..., -0.42742777,\n",
      "         0.09330149,  0.20271398],\n",
      "       [ 0.02124341,  0.17897128,  0.12753735, ..., -0.15113844,\n",
      "        -0.44298932,  0.24029483],\n",
      "       [ 0.02466813,  0.47976586,  0.11080451, ...,  0.26855302,\n",
      "         0.25293833, -0.50465357]], dtype=float32), array([[-0.52785736, -0.3082206 ,  0.07086442, ...,  0.02213223,\n",
      "         0.25459647, -0.14367086],\n",
      "       [-0.0413952 , -0.40342888, -0.02186174, ...,  0.15977456,\n",
      "        -0.03289359,  0.23011401],\n",
      "       [-0.58188373,  0.29241744, -0.48438048, ...,  0.13019788,\n",
      "        -0.53363717,  0.54166162],\n",
      "       ..., \n",
      "       [-0.05804657,  0.14246137, -0.02306126, ..., -0.42575386,\n",
      "        -0.41047162, -0.11202207],\n",
      "       [ 0.0750066 , -0.03699152, -0.06434087, ..., -0.39053732,\n",
      "        -0.43949631, -0.0430114 ],\n",
      "       [ 0.14083496, -0.13397247,  0.12851992, ...,  0.00710457,\n",
      "         0.14597866, -0.4993667 ]], dtype=float32), array([[-0.52374101,  0.36292183, -0.47584838, ..., -0.49332803,\n",
      "         0.19968985,  0.40209699],\n",
      "       [-0.03949733, -0.39992765, -0.13345346, ...,  0.09316185,\n",
      "        -0.05479669, -0.01689535],\n",
      "       [ 0.0130556 , -0.22088736, -0.48270449, ..., -0.09831817,\n",
      "        -0.06573187, -0.21087354],\n",
      "       ..., \n",
      "       [ 0.06034501,  0.06926034,  0.0229017 , ..., -0.42519492,\n",
      "        -0.30422008, -0.30765727],\n",
      "       [-0.10165746, -0.03161893, -0.12365633, ...,  0.02421707,\n",
      "        -0.43816489, -0.11645182],\n",
      "       [ 0.27413252,  0.28375205, -0.35007748, ..., -0.11988926,\n",
      "         0.39441034, -0.49923447]], dtype=float32), array([[-0.52279186,  0.2486234 , -0.13526307, ..., -0.19511418,\n",
      "        -0.48577893,  0.46634284],\n",
      "       [-0.01799544, -0.39494538, -0.02272317, ...,  0.05082199,\n",
      "         0.08685916, -0.18456088],\n",
      "       [-0.45478854,  0.27023095, -0.48266304, ..., -0.11397294,\n",
      "        -0.00297106,  0.44595975],\n",
      "       ..., \n",
      "       [-0.21488173, -0.09029128, -0.18029246, ..., -0.42115393,\n",
      "        -0.07821588,  0.10049649],\n",
      "       [-0.35757107,  0.10523845, -0.33973917, ..., -0.32323027,\n",
      "        -0.43746924,  0.15253432],\n",
      "       [ 0.34948862,  0.6403178 , -0.34969246, ...,  0.49553847,\n",
      "         0.46800193, -0.49837932]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def poids(poid):\n",
    "    k=0\n",
    "    plus_grand=[]\n",
    "    plus_petit=[]\n",
    "    #print poid[0]\n",
    "    res=np.argsort(poid[0],axis=0)\n",
    "    for i in res:\n",
    "        if k<20:\n",
    "            plus_petit.append(poid[0][res[k]])\n",
    "        else:\n",
    "            break\n",
    "        k+=1\n",
    "    k=1\n",
    "    for i in res:\n",
    "        if k<11:\n",
    "            plus_grand.append(poid[0][res[-k]])\n",
    "        else:\n",
    "            break\n",
    "        k+=1\n",
    "    print plus_grand\n",
    "    print \"-------------------\"\n",
    "    print plus_petit\n",
    "    # np.argsort() # 将数组排序之后的index返回\n",
    "poids(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
