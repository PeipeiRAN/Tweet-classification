{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "filename = 'Dataset.csv'\n",
    "\n",
    "nbLignes = 0\n",
    "\n",
    "X_train=[]\n",
    "Y_train=[]\n",
    "\n",
    "for line in open(filename,\"r\"):\n",
    "    ligne=line.split(',')\n",
    "    text=''\n",
    "    for i in range(3,len(ligne)):\n",
    "        if (i!=len(ligne)-1):\n",
    "            text=text+ligne[i]+\",\"\n",
    "        else:\n",
    "            text+=ligne[i]\n",
    "    X_train.append(text)\n",
    "    Y_train.append(ligne[1])\n",
    "    nbLignes=nbLignes+1\n",
    "    \n",
    "X_train=np.asarray(X_train)\n",
    "Y_train=np.asarray(Y_train)\n",
    "\n",
    "X_test=X_train[-300000:]\n",
    "Y_test=Y_train[-300000:]\n",
    "\n",
    "X_train=X_train[1:300001]\n",
    "Y_train=Y_train[1:300001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     is so sad for my APL friend.............\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word(x):\n",
    "    word=\"\"\n",
    "    word_list=[]\n",
    "    flag=True\n",
    "    for i in range(len(x)):\n",
    "        if x[i].isalpha() or x[i]==\"@\" or x[i]==\"&\":\n",
    "            if flag:\n",
    "                word+=x[i]\n",
    "                if i+1==len(x):\n",
    "                    word_list.append(word)\n",
    "            else:\n",
    "                flag=True\n",
    "                word+=x[i]\n",
    "\n",
    "        else:\n",
    "            flag=False\n",
    "            if word!=\"\":\n",
    "                word_list.append(word)\n",
    "            word=\"\"\n",
    "        if word==\"http\" or word==\"www\":\n",
    "            word_list.append(x)\n",
    "            break\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary={}\n",
    "dictionary_inverse={}\n",
    "couts=[]\n",
    "k=0\n",
    "for sentense in X_train:\n",
    "    word_list=get_word(sentense)\n",
    "    for word in word_list:\n",
    "        if word not in dictionary:\n",
    "            dictionary[word]=k\n",
    "            k+=1\n",
    "            dictionary_inverse[k]=word\n",
    "            couts.append(1)\n",
    "        else:\n",
    "            index=dictionary[word]\n",
    "            couts[index]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_dictionary={}\n",
    "new_dictionary_inverse={}\n",
    "k=1\n",
    "for i in range(len(couts)):\n",
    "    if (couts[i]>20):\n",
    "        if (couts[i]<10000):\n",
    "            word=dictionary_inverse[i]\n",
    "            new_dictionary[word]=k\n",
    "            new_dictionary_inverse[k]=word\n",
    "            k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change_into_number(sentense):\n",
    "    word_list=get_word(sentense)\n",
    "    l=[]\n",
    "    for i in range(len(word_list)):\n",
    "        if word_list[i] in new_dictionary:\n",
    "            k=new_dictionary[word_list[i]]\n",
    "            if k not in l:\n",
    "                l.append(k)\n",
    "        else:\n",
    "            l.append(0)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "New_X_train=[]\n",
    "New_X_test=[]\n",
    "for tweet in X_train:\n",
    "    New_X_train.append(change_into_number(tweet))\n",
    "train=np.asarray(New_X_train)\n",
    "\n",
    "for sentense in X_test:\n",
    "    New_X_test.append(change_into_number(sentense))\n",
    "test=np.asarray(New_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 0, 0, 2, 0]\n",
      "                     is so sad for my APL friend.............\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print train[0]\n",
    "print X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nb_y_one(data_set):\n",
    "    k=0\n",
    "\n",
    "    for i in data_set:\n",
    "        if i == 1:\n",
    "            k+=1\n",
    "\n",
    "    return k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_train=np.asarray([int(y) for y in Y_train])\n",
    "Y_test=np.asarray([int (y ) for y in Y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "beacause the data in Y isn't the type of int,\n",
    "so we need to change the form of the Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_Py=[]\n",
    "test_Py=[]\n",
    "\n",
    "nb_train_y1=nb_y_one(Y_train)\n",
    "train_Py.append((len(Y_train)-nb_train_y1)/float(len(Y_train)))\n",
    "train_Py.append(nb_train_y1/float(len(Y_train)))\n",
    "\n",
    "nb_test_y1=nb_y_one(Y_test)\n",
    "test_Py.append((len(Y_test)-nb_test_y1)/float(len(Y_test)))\n",
    "test_Py.append(nb_test_y1/float(len(Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the function nb_y_one aimed to calucale the nb of the jugement which is 1(positive)\n",
    "\n",
    "Also,the train_Py has 2 dimension,train_Py[0] stock the nb of jugement 0\n",
    "train_Py[1] stock the nb of the jugement 1\n",
    "\n",
    "The same for the test_Py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_jug(data_set,label):\n",
    "    positive=[0 for i in range(len(new_dictionary)+1)]\n",
    "    negatif=[0 for i in range(len(new_dictionary)+1)]\n",
    "    for i in range(len(data_set)):\n",
    "        sentence=data_set[i]\n",
    "        for index in sentence:\n",
    "            if label[i]==1:\n",
    "                positive[index]+=1\n",
    "            else:\n",
    "                negatif[index]+=1\n",
    "    return negatif,positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the function word_jug is for calucle how many times the words show in the negatif or positive sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "l1,l2=word_jug(train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_word_juge=[]\n",
    "train_word_juge.append(l1)\n",
    "train_word_juge.append(l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_word_juge has 2 dimension\n",
    "train_word_juge[0] stock how many times the word show in the sentence negative \n",
    "train_word_juge[1] stock how many times the word show in the sentence positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def proba_juge(juge,nby1,nby0):\n",
    "    p0=[]\n",
    "    p1=[]\n",
    "    for i in range(len(juge[1])):\n",
    "        p1.append((juge[1][i]+1)/float((nby1+10000)))\n",
    "        p0.append((juge[0][i]+1)/float((nby0+10000)))\n",
    "    return p0,p1\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p1=P(xi|y=1)   p0=P(xi|y=0)\n",
    "and for the laplace smooth, what i do is add 1 on the numerator, add 10000(the size of the vocabulary) on the denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "train_p=[]\n",
    "p0,p1=proba_juge(train_word_juge,nb_train_y1,(len(Y_train)-nb_train_y1))\n",
    "train_p.append(p0)\n",
    "train_p.append(p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_p[0]=P(xi|y=0)\n",
    "trian_p[1]=P(xi|y=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our goal is to compare the pro of P(z=1|xi) and P(z=0|xi)\n",
    "we have the formula:\n",
    "    P(z=1|xi)=P(xi|z=1)*P(z=1)/the same things\n",
    "    So \n",
    "        if P(xi|z=1)*P(z=1)>P(xi|z=0)*P(z=0)\n",
    "            then the predire label is 1\n",
    "        else\n",
    "            label is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_class(test):\n",
    "    standard_test=test\n",
    "#    for tweet in test:\n",
    "#        standard_test.append(change_into_number(tweet))\n",
    "    standard_test=np.asarray(standard_test)\n",
    "    p1=1\n",
    "    p0=1\n",
    "    label=[]\n",
    "    for tweet in standard_test:\n",
    "        for index in tweet:\n",
    "            p1*=train_p[1][index]\n",
    "            p0*=train_p[0][index]\n",
    "        p1*=train_Py[1]\n",
    "        p0*=train_Py[0]\n",
    "        if p1>p0:\n",
    "            label.append(1)\n",
    "        else:\n",
    "            label.append(0)\n",
    "        p1=1\n",
    "        p0=1\n",
    "    return label\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the loss:  0.30822\n",
      "the acc:  0.69178\n"
     ]
    }
   ],
   "source": [
    "Test=np.asarray(test)\n",
    "label=predict_class(Test)\n",
    "\n",
    "label=np.asarray(label)\n",
    "mis=0\n",
    "for i in range(len(label)):\n",
    "    if Y_test[i]!=label[i]:\n",
    "        mis+=1\n",
    "print \"the loss: \",mis/float(len(label))\n",
    "print \"the acc: \",(len(label)-mis)/float(len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(binary=True, max_features = 4098)\n",
    "ctrain= cv.fit_transform(X_train)\n",
    "ctest= cv.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.string_'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB(alpha=0.5)\n",
    "print type(Y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=0.5, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.fit(ctrain,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74821666666666664"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.score(ctest,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75736666666666663"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(binary=False, max_features = 4098)\n",
    "ctrain= cv.fit_transform(X_train)\n",
    "ctest= cv.transform(X_test)\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "bnb = MultinomialNB(alpha=0.5)\n",
    "bnb.fit(ctrain,Y_train)\n",
    "bnb.score(ctest,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
